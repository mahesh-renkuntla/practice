{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resume_Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNi7gUwXOsqeLIMm1S2p5WS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmahesh6386/practice/blob/main/Resume_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRAdyOwY4oxc",
        "outputId": "0461ab07-c202-49bb-9cdf-603459b63795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import docx\n",
        "import PyPDF2\n",
        "import io \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "import pandas as pd\n",
        "import pdfplumber\n",
        "import pikepdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr-urJ6k6CkN",
        "outputId": "15b83a9f-9c21-49a5-915c-ca54c749f3ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from resume\n",
        "def getText(filename):\n",
        "      \n",
        "    # Create empty string \n",
        "    fullText = ''\n",
        "    if filename.endswith('.docx'):\n",
        "        doc = docx.Document(filename)\n",
        "        \n",
        "        for para in doc.paragraphs:\n",
        "            fullText = fullText + para.text\n",
        "            \n",
        "           \n",
        "    elif filename.endswith('.pdf'):  \n",
        "        with open(filename, \"rb\") as pdf_file:\n",
        "            pdoc = PyPDF2.PdfFileReader(filename)\n",
        "            number_of_pages = pdoc.getNumPages()\n",
        "            page = pdoc.pages[0]\n",
        "            page_content = page.extractText()\n",
        "             \n",
        "        for paragraph in page_content:\n",
        "            fullText =  fullText + paragraph\n",
        "            \n",
        "    else:\n",
        "        try:\n",
        "            import aspose.words as aw\n",
        "            output = aw.Document()\n",
        "        # Remove all content from the destination document before appending.\n",
        "            output.remove_all_children()\n",
        "            input = aw.Document(filename)\n",
        "        # Append the source document to the end of the destination document.\n",
        "            output.append_document(input, aw.ImportFormatMode.KEEP_SOURCE_FORMATTING)\n",
        "            output.save(\"Output.docx\");\n",
        "            doc = docx.Document('Output.docx')\n",
        "        \n",
        "            for para in doc.paragraphs:\n",
        "                fullText = fullText + para.text\n",
        "            fullText = fullText[79:]\n",
        "        except:\n",
        "            filename.endswith(\".zip\")\n",
        "         \n",
        "    return (fullText)"
      ],
      "metadata": {
        "id": "qk4h45LD86OP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove punctuation and tokenize the text\n",
        "def tokenText(extText):\n",
        "   \n",
        "    # Remove punctuation marks\n",
        "    punc = '''!()-[]{};:'\"\\,.<>/?@#$%^&*_~'''\n",
        "    puncText=\" \"\n",
        "    for ele in extText:\n",
        "        if ele in punc:\n",
        "            puncText= extText.replace(ele, \"\")\n",
        "            #print(puncText)\n",
        "    # Tokenize the text and remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    puncText.split()\n",
        "    word_tokens = word_tokenize(puncText)\n",
        "    TokenizedText = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "    TokenizedText = []\n",
        "  \n",
        "    for w in word_tokens:\n",
        "        if w not in stop_words:\n",
        "            TokenizedText.append(w)\n",
        "    return(TokenizedText)"
      ],
      "metadata": {
        "id": "ew_YvH3V9eZv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define key terms dictionary for fixing Role Applied for \n",
        "terms = {'WorkDay ERP':['workday', 'workday consultant', 'workday hcm', 'eib', 'picof', \n",
        "                        'workday studio','nnbound/outbound integrations'],\n",
        "         'Peoplesoft':['peoplesoft', 'pia','ccb','birt','peci','ccw','pum','people tools',\n",
        "                        'peoplesoft implementation','peoplesoft components',\n",
        "                        'peoplesoft dba','peoplesoft admin','peoplesoft admin/dba','peopleSoft fscm', \n",
        "                        'peopletoolsupgrade','peopletools upgrade','process scheduler servers',\n",
        "                        'peoplesoft hrms','peopleSoft consultant','peoplesoft cloud',\n",
        "                        'PeopleSoft migrations','eoplesoft Testing Framework','pure internet architecture'],             \n",
        "         'Database Developer':['sql','sql server', 'ms sql server','msbi', 'sql developer', 'ssis','ssrs',\n",
        "                        'ssms','t-sql','tsql','Razorsql', 'razor sql','triggers','powerbi','power bi',\n",
        "                        'oracle sql', 'pl/sql', 'pl\\sql','oracle', 'oracle 11g','oledb','cte','ddl',\n",
        "                        'dml','etl','mariadb','maria db'],\n",
        "         'Java Developer':['reactjs', 'react js', 'react js developer', 'html', 'React JS'\n",
        "                        'css3','xml','javascript','html5','boostrap','jquery', 'redux','php', 'node js',\n",
        "                        'nodejs','apache','netbeans','nestjs','nest js','react developer','react hooks',\n",
        "                        'jenkins']}"
      ],
      "metadata": {
        "id": "4GUyHAB39ho_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of all key terms to indicate skillset. Include all the key words in the list \n",
        "allTerms = ['workday', 'hcm', 'eib', 'picof','workday hcm',\n",
        "                        'workday studio','nnbound/outbound integrations',\n",
        "                        'peoplesoft', 'pia','ccb','birt','peci','ccw','pum','people tools',\n",
        "                        'peoplesoft implementation','peoplesoft components',\n",
        "                        'peoplesoft dba','peoplesoft admin','peoplesoft admin/dba','peopleSoft fscm', \n",
        "                        'peopletoolsupgrade','peopletools upgrade','process scheduler servers',\n",
        "                        'peoplesoft hrms','peopleSoft consultant','peopledoft cloud',\n",
        "                        'PeopleSoft migrations','eoplesoft Testing Framework','pure internet architecture',\n",
        "                        'sql','sql server', 'ms sql server','msbi', 'sql developer', 'ssis','ssrs',\n",
        "                        'ssms','t-sql','tsql','Razorsql', 'razor sql','triggers','powerbi','power bi',\n",
        "                        'oracle sql', 'pl/sql', 'pl\\sql','oracle', 'oracle 11g','oledb','cte','ddl',\n",
        "                        'dml','etl','mariadb','maria db','reactjs', 'react js', 'react js developer', 'html', \n",
        "                        'css3','xml','javascript','html5','boostrap','jquery', 'redux','php', 'node js',\n",
        "                        'nodejs','apache','netbeans','nestjs','nest js','react developer','react hooks',\n",
        "                        'jenkins']"
      ],
      "metadata": {
        "id": "-rDt1pHn9i0_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read the tokenized text and search for the key words to dermine the Role Applied for\n",
        "def roleApplied (Text):\n",
        "    \n",
        "    # covert the text to lower case\n",
        "    for i in range(len(Text)):\n",
        "        Text[i] = Text[i].lower()\n",
        "    \n",
        "    # Obtain the scores for each area\n",
        "    for area in terms.keys():\n",
        "        if area == 'WorkDay ERP':\n",
        "            for word in terms[area]:\n",
        "                if word in Text:\n",
        "                    role = area\n",
        "                    return (role)\n",
        "                \n",
        "        elif area == 'Peoplesoft':\n",
        "            for word in terms[area]:\n",
        "                if word in Text:\n",
        "                    role = area\n",
        "                    return(role)   \n",
        "                \n",
        "        elif area == 'Database Developer':\n",
        "            for word in terms[area]:\n",
        "                if word in Text:\n",
        "                    role =  area\n",
        "                    return(role)\n",
        "            \n",
        "        elif area == 'Java Developer':\n",
        "             for word in terms[area]:\n",
        "                if word in Text:\n",
        "                    role = area\n",
        "                    return(role)\n",
        "        else:\n",
        "            role = \"Fresher\"\n",
        "            return(role)\n",
        "   # return(role)"
      ],
      "metadata": {
        "id": "NoMdgll-9pZy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract Name and contact details\n",
        "def contactDetails(Text):\n",
        "    name = ''  \n",
        "    for i in range(0,3):\n",
        "        name = \" \".join([name,Text[i]])\n",
        "    return(name)"
      ],
      "metadata": {
        "id": "OCu6Wpbj9sro"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract experience details\n",
        "def expDetails(Text):\n",
        "    global sent\n",
        "   \n",
        "    Text = Text.split()\n",
        "   \n",
        "    for i in range(len(Text)-2):\n",
        "        Text[i].lower()\n",
        "        \n",
        "        if Text[i] ==  'years':\n",
        "            sent =  Text[i-2] + ' ' + Text[i-1] +' ' + Text[i] +' '+ Text[i+1] +' ' + Text[i+2]\n",
        "            return (sent)"
      ],
      "metadata": {
        "id": "TiVSuJUI9ucP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract skill set details\n",
        "def skillSet(Text):\n",
        "    t = []\n",
        "    for i in range(len(Text)):\n",
        "        if Text[i] in allTerms:\n",
        "            if Text[i] in t:\n",
        "                continue\n",
        "            t.append(Text[i]) \n",
        "    return(t)"
      ],
      "metadata": {
        "id": "yLwWFeBr9yoZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/Resumes-20220812T140008Z-001 (1).zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLXGcitcBvqP",
        "outputId": "c5c93064-056d-49c6-86ef-3db4fc1445d5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty Data Frame ResumeText with two columns\n",
        "ResumeText = pd.DataFrame([], columns=['Name','RoleApplied', 'Experience', 'SkillSet','TextInfo'])\n",
        "\n",
        "# Mention the path in your computer where resumes folder is stored\n",
        "path = r\"/tmp/Resumes\"\n",
        "text =[]\n",
        "\n",
        "# Search the directory path and loop through the resume documents and callthe function getText\n",
        "for filename in os.listdir(path):\n",
        "    filename = os.path.join(path, filename)\n",
        "    extText = getText(filename)\n",
        "    #print(type(extText))\n",
        "    tokText = tokenText(extText)\n",
        "    #print(extText)\n",
        "    role = roleApplied(tokText)\n",
        "    Name = contactDetails(tokText)\n",
        "    experience = expDetails(extText)\n",
        "    skills = skillSet(tokText)\n",
        "    NewRow = [Name,role,experience, skills,tokText]  \n",
        "    ResumeText.loc[len(ResumeText)] = NewRow"
      ],
      "metadata": {
        "id": "fRsrLHaL91p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResumeText.head(80)"
      ],
      "metadata": {
        "id": "LbX2B-bcEUY3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}