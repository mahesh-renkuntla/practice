{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmahesh6386/practice/blob/main/Resume_Parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMDWXQOEjuKR",
        "outputId": "7734146c-9293-4e0e-b0cc-41ed0cdc44da"
      },
      "id": "DMDWXQOEjuKR",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d064bbf8",
      "metadata": {
        "id": "d064bbf8"
      },
      "outputs": [],
      "source": [
        "import textract\n",
        "import os\n",
        "import docx\n",
        "import PyPDF2\n",
        "import io \n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "import pandas as pd\n",
        "import pdfplumber\n",
        "import pikepdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ecf1c816",
      "metadata": {
        "id": "ecf1c816"
      },
      "outputs": [],
      "source": [
        "# Function to extract text from resume\n",
        "def getText(filename):\n",
        "      \n",
        "    # Create empty string \n",
        "    fullText = ''\n",
        "    if filename.endswith('.docx'):\n",
        "        doc = docx.Document(filename)\n",
        "        \n",
        "        for para in doc.paragraphs:\n",
        "            fullText = fullText + para.text\n",
        "            \n",
        "           \n",
        "    elif filename.endswith('.pdf'):  \n",
        "        with open(filename, \"rb\") as pdf_file:\n",
        "            pdoc = PyPDF2.PdfFileReader(filename)\n",
        "            number_of_pages = pdoc.getNumPages()\n",
        "            page = pdoc.pages[0]\n",
        "            page_content = page.extractText()\n",
        "             \n",
        "        for paragraph in page_content:\n",
        "            fullText =  fullText + paragraph\n",
        "            \n",
        "    else:\n",
        "        try:\n",
        "            import aspose.words as aw\n",
        "            output = aw.Document()\n",
        "        # Remove all content from the destination document before appending.\n",
        "            output.remove_all_children()\n",
        "            input = aw.Document(filename)\n",
        "        # Append the source document to the end of the destination document.\n",
        "            output.append_document(input, aw.ImportFormatMode.KEEP_SOURCE_FORMATTING)\n",
        "            output.save(\"Output.docx\");\n",
        "            doc = docx.Document('Output.docx')\n",
        "        \n",
        "            for para in doc.paragraphs:\n",
        "                fullText = fullText + para.text\n",
        "            fullText = fullText[79:]\n",
        "        except:\n",
        "            filename.endswith(\".zip\")\n",
        "         \n",
        "    return (fullText)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "0da1d248",
      "metadata": {
        "id": "0da1d248"
      },
      "outputs": [],
      "source": [
        "# Function to remove punctuation and tokenize the text\n",
        "def tokenText(extText):\n",
        "   \n",
        "    # Remove punctuation marks\n",
        "    punc = '''!()-[]{};:'\"\\,.<>/?@#$%^&*_~'''\n",
        "    puncText=\" \"\n",
        "    for ele in extText:\n",
        "        if ele in punc:\n",
        "            puncText= extText.replace(ele, \"\")\n",
        "            #print(puncText)\n",
        "    # Tokenize the text and remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    puncText.split()\n",
        "    word_tokens = word_tokenize(puncText)\n",
        "    TokenizedText = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "    TokenizedText = []\n",
        "  \n",
        "    for w in word_tokens:\n",
        "        if w not in stop_words:\n",
        "            TokenizedText.append(w)\n",
        "    return(TokenizedText)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "7411b38d",
      "metadata": {
        "id": "7411b38d"
      },
      "outputs": [],
      "source": [
        "# Define key terms dictionary for fixing Role Applied for \n",
        "terms = {'WorkDay ERP':['workday', 'workday consultant', 'workday hcm', 'eib', 'picof', \n",
        "                        'workday studio','nnbound/outbound integrations'],\n",
        "         'Peoplesoft':['peoplesoft', 'pia','ccb','birt','peci','ccw','pum','people tools',\n",
        "                        'peoplesoft implementation','peoplesoft components',\n",
        "                        'peoplesoft dba','peoplesoft admin','peoplesoft admin/dba','peopleSoft fscm', \n",
        "                        'peopletoolsupgrade','peopletools upgrade','process scheduler servers',\n",
        "                        'peoplesoft hrms','peopleSoft consultant','peoplesoft cloud',\n",
        "                        'PeopleSoft migrations','eoplesoft Testing Framework','pure internet architecture'],             \n",
        "         'Database Developer':['sql','sql server', 'ms sql server','msbi', 'sql developer', 'ssis','ssrs',\n",
        "                        'ssms','t-sql','tsql','Razorsql', 'razor sql','triggers','powerbi','power bi',\n",
        "                        'oracle sql', 'pl/sql', 'pl\\sql','oracle', 'oracle 11g','oledb','cte','ddl',\n",
        "                        'dml','etl','mariadb','maria db'],\n",
        "         'Java Developer':['reactjs', 'react js', 'react js developer', 'html', 'React JS'\n",
        "                        'css3','xml','javascript','html5','boostrap','jquery', 'redux','php', 'node js',\n",
        "                        'nodejs','apache','netbeans','nestjs','nest js','react developer','react hooks',\n",
        "                        'jenkins']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "500a5039",
      "metadata": {
        "id": "500a5039"
      },
      "outputs": [],
      "source": [
        "# List of all key terms to indicate skillset. Include all the key words in the list \n",
        "allTerms = ['workday', 'hcm', 'eib', 'picof','workday hcm',\n",
        "                        'workday studio','nnbound/outbound integrations',\n",
        "                        'peoplesoft', 'pia','ccb','birt','peci','ccw','pum','people tools',\n",
        "                        'peoplesoft implementation','peoplesoft components',\n",
        "                        'peoplesoft dba','peoplesoft admin','peoplesoft admin/dba','peopleSoft fscm', \n",
        "                        'peopletoolsupgrade','peopletools upgrade','process scheduler servers',\n",
        "                        'peoplesoft hrms','peopleSoft consultant','peopledoft cloud',\n",
        "                        'PeopleSoft migrations','eoplesoft Testing Framework','pure internet architecture',\n",
        "                        'sql','sql server', 'ms sql server','msbi', 'sql developer', 'ssis','ssrs',\n",
        "                        'ssms','t-sql','tsql','Razorsql', 'razor sql','triggers','powerbi','power bi',\n",
        "                        'oracle sql', 'pl/sql', 'pl\\sql','oracle', 'oracle 11g','oledb','cte','ddl',\n",
        "                        'dml','etl','mariadb','maria db','reactjs', 'react js', 'react js developer', 'html', \n",
        "                        'css3','xml','javascript','html5','boostrap','jquery', 'redux','php', 'node js',\n",
        "                        'nodejs','apache','netbeans','nestjs','nest js','react developer','react hooks',\n",
        "                        'jenkins']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b4926138",
      "metadata": {
        "id": "b4926138"
      },
      "outputs": [],
      "source": [
        "# Function to read the tokenized text and search for the key words to dermine the Role Applied for\n",
        "def roleApplied (Text):\n",
        "    \n",
        "    # covert the text to lower case\n",
        "    for i in range(len(Text)):\n",
        "        Text[i] = Text[i].lower()\n",
        "    \n",
        "    # Obtain the scores for each area\n",
        "    for area in terms.keys():\n",
        "        if area == 'WorkDay ERP':\n",
        "            for word in terms[area]:\n",
        "                if word in Text:\n",
        "                    role = area\n",
        "                    return (role)\n",
        "                \n",
        "        elif area == 'Peoplesoft':\n",
        "            for word in terms[area]:\n",
        "                if word in Text:\n",
        "                    role = area\n",
        "                    return(role)   \n",
        "                \n",
        "        elif area == 'Database Developer':\n",
        "            for word in terms[area]:\n",
        "                if word in Text:\n",
        "                    role =  area\n",
        "                    return(role)\n",
        "            \n",
        "        elif area == 'Java Developer':\n",
        "             for word in terms[area]:\n",
        "                if word in Text:\n",
        "                    role = area\n",
        "                    return(role)\n",
        "        else:\n",
        "            role = \"Fresher\"\n",
        "            return(role)\n",
        "   # return(role)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "63bb152f",
      "metadata": {
        "id": "63bb152f"
      },
      "outputs": [],
      "source": [
        "# Function to extract Name and contact details\n",
        "def contactDetails(Text):\n",
        "    name = ''  \n",
        "    for i in range(0,3):\n",
        "        name = \" \".join([name,Text[i]])\n",
        "    return(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "2e4b654c",
      "metadata": {
        "id": "2e4b654c"
      },
      "outputs": [],
      "source": [
        "# Function to extract experience details\n",
        "def expDetails(Text):\n",
        "    global sent\n",
        "   \n",
        "    Text = Text.split()\n",
        "   \n",
        "    for i in range(len(Text)-2):\n",
        "        Text[i].lower()\n",
        "        \n",
        "        if Text[i] ==  'years':\n",
        "            sent =  Text[i-2] + ' ' + Text[i-1] +' ' + Text[i] +' '+ Text[i+1] +' ' + Text[i+2]\n",
        "            return (sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6d81c591",
      "metadata": {
        "id": "6d81c591"
      },
      "outputs": [],
      "source": [
        "# Function to extract skill set details\n",
        "def skillSet(Text):\n",
        "    t = []\n",
        "    for i in range(len(Text)):\n",
        "        if Text[i] in allTerms:\n",
        "            if Text[i] in t:\n",
        "                continue\n",
        "            t.append(Text[i]) \n",
        "    return(t)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EljZ3JQndPK",
        "outputId": "e67bc8d3-8bf8-4d4a-9c95-df4f16e93368"
      },
      "id": "5EljZ3JQndPK",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3d107375",
      "metadata": {
        "id": "3d107375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "7b8829f2-ada1-4178-a412-18fd430cf422"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-42f405e2f763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print(extText)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroleApplied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontactDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mexperience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mskills\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskillSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-4501278c5f36>\u001b[0m in \u001b[0;36mcontactDetails\u001b[0;34m(Text)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# Create an empty Data Frame ResumeText with two columns\n",
        "ResumeText = pd.DataFrame([], columns=['Name','RoleApplied', 'Experience', 'SkillSet','TextInfo'])\n",
        "\n",
        "# Mention the path in your computer where resumes folder is stored\n",
        "path = r\"/content/gdrive/MyDrive/Resumes\"\n",
        "text =[]\n",
        "\n",
        "# Search the directory path and loop through the resume documents and callthe function getText\n",
        "for filename in os.listdir(path):\n",
        "    filename = os.path.join(path, filename)\n",
        "    extText = getText(filename)\n",
        "    #print(type(extText))\n",
        "    tokText = tokenText(extText)\n",
        "    #print(extText)\n",
        "    role = roleApplied(tokText)\n",
        "    Name = contactDetails(tokText)\n",
        "    experience = expDetails(extText)\n",
        "    skills = skillSet(tokText)\n",
        "    NewRow = [Name,role,experience, skills,tokText]  \n",
        "    ResumeText.loc[len(ResumeText)] = NewRow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a11ec33",
      "metadata": {
        "id": "2a11ec33"
      },
      "outputs": [],
      "source": [
        "ResumeText.head(80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Resume Parser.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}